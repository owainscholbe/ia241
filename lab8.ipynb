{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### job one\n",
    "\n",
    "Data Analyst\n",
    "\n",
    "Cathexis\n",
    "\n",
    "[link](https://careers-cathexiscorp.icims.com/jobs/1341/data-analyst-active-secret-clearance/job?mode=job&iis=Indeed&iisn=Indeed.com&mobile=false&width=1100&height=500&bga=true&needsRedirect=false&jan1offset=-300&jun1offset=-240)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### job two\n",
    "\n",
    "Intelligence Analyst\n",
    "\n",
    "General Dynamics Information Technology\n",
    "\n",
    "[link](https://gdit.com/careers/rq34113-intelligence-analyst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlwt\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "book = xlwt.Workbook()\n",
    "sheet_test = book.add_sheet('word_count')\n",
    "i = 0\n",
    "sheet_test.write(i, 0, 'word')\n",
    "sheet_test.write(i, 1, 'count')\n",
    "sheet_test.write(i, 2, 'ratio')\n",
    "\n",
    "with open('job1.txt', 'r', encoding = 'utf-8', errors = 'ignore') as text_word:\n",
    "    \n",
    "    word_list = [i for i in text_word.read().lower().split()\\\n",
    "                if i not in stop]\n",
    "    word_total = word_list.__len__()\n",
    "    \n",
    "    count_result = Counter(word_list)\n",
    "    for result in count_result.most_common(10):\n",
    "        i += 1\n",
    "        sheet_test.write(i, 0, result[0])\n",
    "        sheet_test.write(i, 1, result[1])\n",
    "        sheet_test.write(i, 2, (result[1]/word_total))\n",
    "        \n",
    "book.save('jobs1.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "book = xlwt.Workbook()\n",
    "sheet_test = book.add_sheet('word_count')\n",
    "i = 0\n",
    "sheet_test.write(i, 0, 'word')\n",
    "sheet_test.write(i, 1, 'count')\n",
    "sheet_test.write(i, 2, 'ratio')\n",
    "\n",
    "with open('job2.txt', 'r', encoding = 'utf-8', errors = 'ignore') as text_word:\n",
    "    \n",
    "    word_list = [i for i in text_word.read().lower().split()\\\n",
    "                if i not in stop]\n",
    "    word_total = word_list.__len__()\n",
    "    \n",
    "    count_result = Counter(word_list)\n",
    "    for result in count_result.most_common(10):\n",
    "        i += 1\n",
    "        sheet_test.write(i, 0, result[0])\n",
    "        sheet_test.write(i, 1, result[1])\n",
    "        sheet_test.write(i, 2, (result[1]/word_total))\n",
    "        \n",
    "book.save('jobs2.xls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"job1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"job2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'helps', 'Analyst', 'CATHEXIS,', 'improvement', 'contingent', 'Experience', 'trends', 'Help', 'techniques', 'operation', 'Washington,', 'million', 'clients', 'provide', 'visualizations', 'direction', 'contract', 'methodologies', 'from', 'working', 'Contract', '2019', 'end-user', 'course', 'Provide', 'Access', 'this', 'Agencies,', 'Demonstrate', 'people', 'Identify', 'incomplete', 'Tableau', 'organizational', 'MAX.Gov', 'category', 'at', 'Governance', 'laws,', 'etc', 'Approach', 'Modeling', 'regarding', 'Clearance', 'SAO,', 'Establish', 'standards,', 'imperfect', 'teams', 'opportunities,', 'proficiency', 'proper', 'Assist', 'award.', 'tools,', 'Virtual', 'Let', 'using,', 'Metro', 'development', 'eligible', 'Process', 'program-wide', 'ingesting,', 'extension', 'sources', 'System-Next', 'ingest', '(i.e.', 'enable', 'regulation,', 'Lab', 'is', 'Familiarity', 'DoD,', 'such', 'leader', 'actively', 'across', 'Events', 'Strong', 'Familiar', 'operational', 'Washington', 'Systems', 'Security', 'About', 'CPS', 'Employer', 'on', 'procurement', 'expertise,', 'as,', 'identified', 'Employer/Veterans/Disabled', 'jobs:', 'shared', 'Gov.Spend.org,', 'DC', 'project', 'systems', 'Bachelors', 'category.', 'spend,', 'Tableau,', 'Cookies,', 'shall', 'retaining,', 'templates', 'acquisition', 'minimum,', 'reporting,', 'predictive', 'verbal', '12', 'Recommend', 'Jobs', 'Army', 'You', 'CMPSO,', 'Advice', 'PSO', 'improve', 'translate', 'Subject', 'years)', 'Indeed', 'data.', 'Procurement', 'In', 'address', 'complex', 'government', 'descriptive,', 'optimization.', 'Proven', 'visualizing', 'role,', 'compliant/consistent', 'Category', 'Terms', 'Candidates', 'This', 'platforms', 'include', 'framework.', 'quality', 'Armys', 'analyze', 'Expertise', 'R,', 'principles', 'storing,', 'compliance', 'Managers', 'regulations,', 'problems', '-', 'teams).', 'federal', 'Demonstrated', 'synthesis', 'employed', 'platform', 'open', 'must', 'Equal', 'requests', 'exploratory', 'Maintain', 'policy', 'formerly', 'robust', 'Departments.', 'DC.', 'additional', 'degree', 'days', 'opportunities', 'position', '(minimum', 'Work', 'Generation,', 'integrate', 'area.', 'FPDS-NG,', 'use', 'managers.', 'effectiveness', 'expertise', 'are', 'accessing,', 'Opportunity', 'that', 'measuring', 'tracking', 'community', 'Responsibilities', 'identify', 'contract.', 'data;', 'Center', 'program', 'Support', 'Matter', 'Enterprise', 'CM', 'LLC,', 'dashboards', 'methodologies.', 'high', 'Hiring', 'Services,', 'processes,', 'Tools', 'Data', 'leading', 'capable', 'aesthetic', 'goals', 'gaps', 'help', 'looking', 'implementation', 'Browse', 'data', 'policies,', 'Professional', 'exploiting', 'required.', 'Management', 'tools', 'priorities', 'objectives', 'excellence', 'analytic', 'market', 'entry', 'over', 'aligning', 'resolve', 'collection', 'analytics.', 'Expert', 'policies', 'reside', 'SQL.', 'Privacy', 'analytics', 'knowledge', 'statute,', 'business', 'application', 'design', 'Over', 'Career', 'compliant', 'training', 'used', 'contractor', 'efforts.', 'activities', 'using', 'strategic', '10', 'Address', 'management', 'delivery', 'approaches', 'A', 'Find', 'evolving', 'sponsorship.', 'including', 'Acquisition', 'Federal', 'will', 'approach', 'data,', 'Dashboards,', 'define', 'stories', 'Employers', 'developing', 'Qlik', 'get', 'performance'}\n",
      "{'research', 'presentation', 'Office', 'both', 'executing', 'strong', 'all', 'including,', 'oral),', '(c)', 'to,', 'searches', 'hours', '2+', 'Act', 'Chief', 'teams;', 'detail,', '(e)', 'Security,', 'National', 'equivalent', '0+', '(a)', 'requests,', 'enforcement,', 'its', 'local', 'Justice,', 'Intelligence,', 'identifying,', 'would', 'daily', 'missions', 'under', 'substitutes;', 'new', 'Exceptional', 'Studies,', 'interpersonal', 'determined', 'summaries', 'pre-trial', 'adequate', 'REQUIRED', 'Analysts', 'task', 'preparation', 'limited', 'Commission', 'prosecution', 'diverse', 'AND', 'substitutions;', 'combination)', 'effectively', 'conducting', 'work', 'years', 'WITH', 'Requirements:', 'Ability', 'international', 'Travel', 'Administration', 'intelligence', 'convened', 'to:', 'missions,', 'discipline', 'but', 'aspects', 'relevant', '(e.g.,', 'preparation,', \"Bachelor's\", 'criminal', 'resourcing,', 'DESIRED', '(OCP)', 'refining,', 'directed', 'managing', 'Prosecutor,', 'discovery-related', 'fast-paced', 'necessary,', 'trial', 'OCP', 'discovery,', 'creation', 'law', 'environment', 'Information', 'demanding', 'providing', 'skills,', 'groups', \"organization's\", 'documents', 'OCP.', 'Masters', 'Paralegal', 'discovery', 'and/or', 'legal', 'travel,', '(both', 'progressive', 'existing', 'litigation', 'defense', 'occasional', '2009.', 'attention', 'simultaneous', 'retrieving', 'crafting', 'pretrial', 'Legal', 'Commissions', '(SCI)', '(or', 'international.', 'independently', 'performing', '(d)', 'assisting', 'Studies)', '(b)', '0-25%', 'response', 'products;', 'Qualifications:', 'Knowledge', 'ability', 'redactions,', 'multiple,', 'Criminal', 'excellent', 'analytical', 'Prosecutor', 'require', 'Compartmented', 'applicable', '(OMC)', 'Sensitive', 'Top', 'counsel', 'comprehensive', 'eligibility', 'task-oriented', 'products,'}\n"
     ]
    }
   ],
   "source": [
    "with open('job1.txt', 'r', encoding = 'utf-8', errors = 'ignore') as job1:\n",
    "    with open('job2.txt', 'r', encoding = 'utf-8', errors = 'ignore') as job2:\n",
    "        job1_str = job1.read()\n",
    "        job2_str = job2.read()\n",
    "\n",
    "        job1_set = set(job1_str.split())\n",
    "        job2_set = set(job2_str.split())\n",
    "        \n",
    "        print(job1_set.difference(job2_set))\n",
    "        print(job2_set.difference(job1_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "with open('job1.txt', 'r', encoding = 'utf-8', errors = 'ignore') as job1:\n",
    "    with open('job2.txt', 'r', encoding = 'utf-8', errors = 'ignore') as job2:\n",
    "        job1_str = job1.read()\n",
    "        job2_str = job2.read()\n",
    "        print(fuzz.token_sort_ratio(job1_str, job2_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
